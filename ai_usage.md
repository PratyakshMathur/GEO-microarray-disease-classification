
This project made use of AI assistance throughout different stages of development to improve understanding, speed, and accuracy. Below is a summary of how AI was used.



## **➡️ Biological Inference & Data Interpretation**

AI was used to clarify the biological meaning behind gene expression values, cancer vs. normal sample differences, probe-level signals, platform variations, and the reasoning behind merging datasets. It helped interpret QC outputs and understand how biological noise, batch effects, and platform-specific differences influence downstream results.



## **➡️ Learning Coding Syntax & Implementation**

AI assisted in understanding Python syntax, GEOparse usage, DataFrame operations, plotting functions, and best practices for structuring a bioinformatics pipeline. It provided explanations for complex code blocks and guided the proper usage of libraries such as pandas, NumPy, scikit-learn, and matplotlib.



## **➡️ Understanding ComBat & Batch Correction**

The logic of ComBat, empirical Bayes correction, batch variable handling, and how to apply it on multi-platform microarray datasets was explained using AI. This helped ensure correct application of ComBat, including preprocessing steps, normalization, and verifying the effectiveness of correction using PCA.


## **➡️ Dataset Understanding & Selection**

AI was used to evaluate GEO datasets, understand platform compatibility (GPL96 vs GPL571, etc.), label quality, probe structure, metadata fields, and dataset merging strategies. It assisted in identifying which datasets were suitable, how to check sample distribution, and how to perform QC on each dataset.



## **➡️ Research Paper Interpretation**

AI helped interpret research papers related to microarray pipelines, cancer classification, batch correction, and feature selection. This included summarizing methodologies, comparing approaches, and understanding how similar studies handled dataset merging and normalization.



